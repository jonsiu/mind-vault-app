## AI performance optimization for desktop apps

- **Background Processing**: Run AI inference in background threads
- **Non-Blocking UI**: Keep UI responsive during AI operations
- **Progress Indicators**: Show progress for long AI operations
- **Cancellable Operations**: Allow canceling slow AI operations
- **Result Caching**: Cache AI results for identical inputs
- **Batch Processing**: Batch multiple AI requests when possible
- **Lazy Loading**: Lazy load AI models and features
- **Memory Management**: Manage model memory usage; unload when not needed
- **GPU Utilization**: Use GPU for inference when available
- **Model Selection**: Offer speed vs quality tradeoffs
- **Preloading**: Preload models on app startup or before first use
- **Streaming**: Stream results incrementally for faster perceived performance
- **Debouncing**: Debounce AI requests triggered by user input
- **Resource Monitoring**: Monitor CPU/memory usage; throttle if needed
